BUILDING A SIMPLE DOCKERFILE:

1). Create a file caled Dockerfile inside your project directory

2). Base your Docker image on a "base container" (so you're nor reinventing the
wheel). In this case we are using node:12-stretch as a base:

FROM node:12-stretch

3). Tell it what to do when it starts up:

CMD ["node", "-e", "console.log(\"Hello World\")"]

NOTE: -e means immediately execute the string of code (within the node environment)
You can run: node -e "console.log(\"Hello World\")" within any environment that
has node and it will work as expected.

NOTE: docker run -it node:stretch-12 will drop you into the node REPL. That's what
the node:12-stretch dockerfile is set up to do via the CMD instruction. We're
overriding that call to the REPL with out custom CMD instruction. The last CMD
found in the dockerfile will be the one that is executed, so if you have two
CMD instructions in your dockerfile like so:

CMD ["node", "-e", "console.log(\"hello"\)"]
CMD ["node", "-e", "console.log(\"hello again"\)"]

when you run your custom container, "hello again" will print, not "hello"


NOTE: You don't need to specify a CMD line (if you are basing your container off
of another one at least). If you don't it will run the default CMD instruction.
You can also run commands that you specify that overrun the CMD instruction like
you would any other conatiner (docker run [CID] ls)

4). From the directory your dockerfile is sitting in you can run:

docker build .

It will assume that you named your dockerfile Dockerfile (if not you can specify)

5). To run your custom container:

docker run [IMAGE ID]

NOTE: you can find the Image ID by running "docker image list" or "docker
images"

6). Give your container a custom tag:

docker build --tag my-node-app .

NOTE: this will default the tage to my-node-app:latest
It's better to version your containers (my-node-app:1.0.0)

7). When you make new versions of the container, it stores the history and you
can run older versions:

    1). docker build --tag my-node-app:1
    2). change the CMD slightly so it prints something different now
    3). docker build --tag my-node-app:2
    4). docker build --tag my-node-app:1

doing this you can see that you can run different versions of your container

NOTE: That when rebuilding the container, the image ID appears to stay the same
until you change the tag at which point a new image and IID is generated.

----------------------------------------------------------------------------------

BUILDING A NODE.JS APP:

Let's say we have a basic node server (index.js):

// Import the http core module
const http = require("http");

// Create an http server on port 3000
http
    .createServer(function(request, response) {
        // Upon receiving a request print that you received it
        console.log("request received");
        // Display a custom response
        response.end("omg hi", "utf-8");
    })
    .listen(3000);

console.log("server started");


running that locally with "node index.js" you'll see the "server started" printout
and then if you go to localhost:3000 in the browser, you'll see "omg hi" displayed on the page.

NOTE: if you look at what is printed out on the terminal, you should see:

server started
request received
request received

the reason why there are two request received printouts is that running index.js
from the browser creates two requests. One of them is requesting the favicon to
display.


We can also package this node code into a custom container that we could use to
run this server:

1). Create a Dockerfile in the same directory as index.js

2). In that Dockerfile:

FROM node:12-stretch

COPY index.js index.js

CMD ["node", "index.js"]


NOTE: The COPY command copies the source (first path) file into the container at
the destination path (second path). If we didn't do this, our container would not
be able to access index.js.


3). Build the custom container:

docker build -t my-node-app .

This will override the previous container we made but that's fine

NOTE: The output of this command shows that during the build command, docker
is actually running each instruction sequentially and creating a valid container
for each step.


4). If you run the node server we created from within the container we made:

docker run my-node-app

We see that if we go to localhost:3000 in the browser, the browser cannot establish
a connection. This is because by default our container is not given access to the
network (certain namespaces are unshared).

You can also see that you can't CTRL+C to end the Node server in the container.
This is because Node does not respond to these kinds of signals (SIGINT in this
case). When we press CTRL+C we're telling docker to pass the SIGINT along to
Node and Node does not process it. There are a couple of ways to solve this
problem:

    1). Deal with it within the Node index.js file we created (process.on
    ('SIGTERM') end the server)

    2). Open another terminal and docker kill the process

    3). When you run your node app within the container use the --init flag:

    docker run --init --rm my-node-app

    This will run the container with a module called tini which will proxy the
    node process and will deal with the SIGTERM/SIGINT signals for you (the --rm
    flag just removes the container once it runs). If you want to run tini in prod
    it's better to go into you Dockerfile, install tini and then run Node from tini
    so that it's built into the container.

    TODO: try to do this right both with tini and dealing with SIGs in index.js



5). To run the container so that it can access port 3000 we run:

docker run --init --rm --publish 3000:3000 my-node-app

NOTE: you could route ports like 3000:8000 (ACTUALLY i tried routing like this
and it didn't work). Allowing port access is probably something you want to be
doing at runtime, so using publish is probably a better idea than using the expose
instruction in the Dockerfile in this case

--------------------------------------------------------------------------------------------

DEALING WITH SIGNALS WITH DOCKER:

The process of passing along signals in docker (at least when running node) is
tricky. I tried adding code that would deal with signals inside of index.js:

'use strict';
const process = require('process');
const http = require('http');

var server = http
  .createServer((req, res) => {
    console.log('Request received');
    res.writeHead(200, {'Content-Type': 'text/plain'});
    res.end('Hello World\n');
  })
  .listen(3000, '0.0.0.0');

  console.log('server started\n');
  // Confirm that this process is running with PID 1
  console.log('PID = ' + process.pid);

  var signals = {
    'SIGINT': 2,
    'SIGTERM': 15
  };

  function shutdown(signal, value) {
    server.close(() => {
      console.log('server stopped by ' + signal);
      process.exit(128 + value);
    });
  }

  Object.keys(signals).forEach((signal) => {
    process.on(signal, () => {
      shutdown(signal, signals[signal]);
    });
  });


Credit to:
https://medium.com/@gchudnov/trapping-signals-in-docker-containers-7a57fdda7d86

https://medium.com/@becintec/building-graceful-node-applications-in-docker-4d2cd4d5d392


This code works great when running node locally outside of a container. It handles signals
does what you would expect. Unfortunately, when you run index.js from a container the
signal is never passed through properly. I believe that when we run the container as it's
built initially, the Node command running the http server is running with PID=1. It seems
that whatever command is in the CMD=[]; line in the dockerfile/executed first has PID=1
and I need to look into why this is causing issues (research online seems to point that it does).
In order to see whether or not the PID made a difference I tried the following (not sure this
is actually sound logic):

1). Created a new version of my-node-app container where in the dockerfile i commented out
the CMD that runs the index.js and just run bash instead.

2). I ran the container in -it mode so that I could launch the server manually:

docker -it --rm my-node-app:1.1.0
node index.js

3). In my index.js code I print out the PID, but I can also just run ps aux. Using that PID,
I passed a SIGINT signal to the node process running within the modified node container:

docker exec [CONTAINER NAME] kill -SIGINT [PID of node index.js running inside the container]

This worked and the signal was handled as specified in index.js. Given that the docker
exec command to kill the process with SIGINT was run from outside the container, I assume
that this mimics what happens when I try to CONTROL+C when running my-node-app version 1.
The main difference is that in the first version, the http server is running on PID 1.
Once again, I'm not sure that my assumptions are correct.


    WRITING A CUSTOM INIT PROCESS:

    https://hackernoon.com/my-process-became-pid-1-and-now-signals-behave-strangely-b05c52cc551c

    1). Create a simple (python) script that just sleeps:

    import subprocess
    subprocess.call(["sleep", "100"])

    2). Run it locally and kill it successfully with SIGTERM (kill [PID] command)

    3). Create a simple dockerfile:

    FROM ubuntu:20.04

    RUN apt-get update
    RUN apt-get install -y python
    COPY mypy.py /srv/

    CMD ["python", "/srv/mypy.py"]


    4). Run the container interactively:

    docker exec -it [CID] bash

    5). Confirm that the process id of the python script is 1 using the ps command (ps -ef)

    6). Try killing the python process (SIGTERM kill [PID] command)

    7). Confirm that the process is still running despite the SIGTERM signal

    NOTE: when runnning a similar setup with Go, it seems to let you SIGTERM.
    A process running as PID 1 inside a container is treated specially by Linux: it ignores
    any signal with the default action. As a result, the process will not terminate on SIGINT
    or SIGTERM unless it is coded to do so. That being said, even when we tried defining
    handlers in our index.js file, it didn't work so I'm not sure what's happening. Also
    PID 1 is responsible for some things behind the scenes so killing it is not always
    adviseable.

    What we'd like to do instead is run a different process as PID 1 that proxy's signals from
    outside the container into the script/server inside the container. We also want that
    process to take care of some other standard initialization things.

    As BH mentioned, Tini does this for us and ships with Docker.


    NOTE: I tried writing my own init based off but I'm going to leave it alone for now and
    come back to it. Just a few notes though:

    1). The basic idea of the init process is that it will take the name of the process
    we want to run as an argument and execute it for us. After starting the process it's
    important to make a Wait call so as to avoid spawning zombie processes.A child that
    terminates, but has not been waited for becomes a "zombie". The kernel maintains a
    minimal set of information about the zombie process (PID, termination status, resource
    usage information) in order to allow the parent to later perform a wait to obtain
    information about the child. As long as a zombie is not removed from the system via a wait,
    it will consume a slot in the kernel process table, and if this table fills, it will
    not be possible to create further processes.

    2). Then you have to write code in your init script to listen for signals and handle
    them. The handler function will ultimately make some sort of system call to kill
    the process via its PID.

    3). PID 1 is also responsible for cleaning up Zombie processes and reparenting
    orphaned processes (A -spawns-> B -spawns-> C. Now if B is killed C does not have a parent
    process and PID 1 is responsible for making C's parent process A. When C exits, A receives
    a SIGCHILD signal and is responsible for calling wait on C to clean up this Zombie process).

    4). You also have to deal with the situation where process B failed to call Wait on C
    and when B is killed, a Zombie C process becomes the child of A. This has to be dealt
    with as well and seems a little tricky (lookup WNOHANG, SIGCHILD, wait4).

    5). Sidenote:  To avoid getting hung up on tzdata config question
    about geographic zone during docker build, I added ARG DEBIAN_FRONTEND=noninteractive to the
    Dockerfile.

--------------------------------------------------------------------------------------------------

BACK TO THE NODE APP:

For now, call:

docker run --init --rm --publish 3000:3000  my-node-app

in order to call tini and not have to worry about the signals. We also call publish to allow
the node app to have access to port 3000.
NOTE: docker-init will be PID=1 and the node index.js process will have a different PID



RUN NODE APP:

Generally it's a bad idea to let processes run as the root user unless they absolutely need to.
That being said, it's usually the default behavior for containers. Some containers come
with pre-made groups and users and others do not. Default Ubuntu does not, but Node comes with
the node group and the node user, which we will want to be using. To change users, add the
following to your dockerfile:

USER node


NOTE: if we put the USER node line before the COPY line, the file we wish to copy will be
copied as the root user. This will mean that the node user won't be able to modify or execute
the file we copied. To solve this, we want to chown the file (requires specifying a user and
group):

USER node

COPY --chown=node:node index.js index.js


NOTE: Instead of the COPY instruction you could use ADD. ADD allows you to reach out to the
internet to bring in a file and also to unzip files (works with tar too). Generally, it's
best to use COPY unless you have specific needs tht can only be addressed by ADD.

We also want to create a directory structure that keeps things a bit more organized (currently
everything is just being dropped into the root directory):

WORKDIR /home/node/code

This will make a code directory into the preexisting home directory of the node user (/home/node).
The node user owns /home/code so this is a good place to put any code that we want it to run.

CORRECTION: the directory you list under WORKDIR will actually be owned by root so this is not
the way to do it. See next section
-------------------------------------------------------------------------------------------------

A MORE COMPLICATED NODE.JS APP (WITH DEPENDENCIES):

One of the main advantages Docker is that we can freeze and maintain dependencies.

If you want to create a project that has dependencies locally you can:

npm init -y

npm install [dependencies]

NOTE: in this case we're installing @hapi/hapi and hapi-pino

This will create the node_modules directory, a package.json and package-lock.json file

This is all well and good for running things locally, but running an app with dependencies
in a container is a little more complicated.

With the following dockerfile you can run an app fine, but only because all the dependencies
are already installed locally:

FROM node:12-stretch

USER node

WORKDIR /home/node/code

COPY --chown=node:node . .

CMD ["node", "index.js"]


If you running this in CI, the modules won't be there since we don't commit them. Also,
node has the concept of native modules. Some of the modules are written in C and build for
specific OS's. If you have a native module on one OS and then copy it into the container,
it won't work properly. The solution is to run NPM install inside the container:


FROM node:12-stretch

USER node

WORKDIR /home/node/code

COPY --chown=node:node . .

RUN npm ci

CMD ["node", "index.js"]



BEST PRACTICE: Running npm ci is better than npm install because it adheres to what's in the
package-lock.json and it's also faster.

NOTE: WORKDIR is always set by root, so the directory we're trying to install node modules
to is going to be owned by root not the node user. This will cause permission errors. The
solution is to create the directory as the node user:

FROM node:12-stretch

USER node

RUN mkdir /home/node/code

WORKDIR /home/node/code

COPY --chown=node:node . .

RUN npm ci

CMD ["node", "index.js"]

You can check the permissions on the copied files by running the ls -lsah command in the
container:

docker run --init --rm --publish 3000:3000 my-node-app ls -lsah


NOTE: in the index.js file with the hapi setup, we have to specify host: "0.0.0.0" instead
of localhost. Otherwise it won't work. Also, prettyPrint is deprecated and has been
replaced with pino-pretty but I couldn't quite get it to work, so I just removed prettyPrint
for now since the goal of these exercises is not to make the javascript work.
------------------------------------------------------------------------------------------------

EXPOSE VS PUBLISH:

Instead of running --publish 3000:3000 you could add the instruction EXPOSE 3000 to your dockerfile
you would then run:

docker run --init --rm --detach -P my-node-app

The -P would choose a port to map from 3000. So you would have to run:

docker ps

Then under PORTS you would find the port to navigate to in your browser. If you see:

0.0.0:32768->3000/tcp

you would know that docker has exposed what's on the container port 3000 to 32768 outside the
container (?), so you would navigate to localhost:32768

This tends to be less convenient than --publish so it's probably not worth doing.

-------------------------------------------------------------------------------------------------------

LAYERS:

The order of instructions in a Dockerfile matters a lot because docker builds containers layer by layer.
Docker caches the images built on instruction at a time so that upon rebuild it just rebuilds the container
from the change onwards. So if we look at the following instructions:

FROM node:12-stretch

USER node

RUN mkdir /home/node/code

WORKDIR /home/node/code

COPY --chown=node:node . .

RUN npm ci

EXPOSE 3000

CMD ["node", "index.js"]


If you make any change to the index.js file (say change the server should run on), Docker will
rebuild the image from the COPY instruction, since a change has been made in the files in the
current directory. It then keeps building by executing the next command which is RUN npm ci.
What this means is that all the downloading of dependencies will happen again, even though we
haven't changed anything in the node modules directory, package.json, or package-lock.json.

Therefore, it's better to COPY the package.json and package-lock.json files over to the container
first, then RUN npm ci within the container and only then copy the rest of the files. Next time
something changes in the index.js file, so long as no changes were made with the packages/dependencies,
all the node modules will be cached and docker will not have to download them again upon a rebuild:

FROM node:12-stretch

USER node

RUN mkdir /home/node/code

WORKDIR /home/node/code

COPY --chown=node:node package-lock.json package.json ./

RUN npm ci

COPY --chown=node:node . .

EXPOSE 3000

RUN ["node", "index.js"]



NOTE: BH says we need the slash at the end of the first copy to tell it to put it into
the directory. One concern with caching the packages this way is that if a security patch
comes out, the way that package-lock.json (and package.json) is built is with the "^" before
the dependceny version:

"dependencies": {
    "@hapi/hapi: "^18.4.0",
    "hapi-pino": "^6.3.0"
}

The "^" means that these are relative versions and upon running npm ci the security patches
would be downloaded and installed automatically. Unfortunately, the way we have the npm modules
cached, the container would not receive those security updates ("stale cache"). Generally for development, this
is not a big deal.
-----------------------------------------------------------------------------------------------------------------

DOCKERIGNORE

Same format and purpose as a gitignore file. Create a .dockerignore file and exclude any files you don't want
to be moved into your container:

.git/
node_modules/

NOTE: your git files are actually a security vulnerability. You don't want to publish them in production












BUILDING A SIMPLE DOCKERFILE:

1). Create a file caled Dockerfile inside your project directory

2). Base your Docker image on a "base container" (so you're nor reinventing the
wheel). In this case we are using node:12-stretch as a base:

FROM node:12-stretch

3). Tell it what to do when it starts up:

CMD ["node", "-e", "console.log(\"Hello World\")"]

NOTE: -e means immediately execute the string of code (within the node environment)
You can run: node -e "console.log(\"Hello World\")" within any environment that
has node and it will work as expected.

NOTE: docker run -it node:stretch-12 will drop you into the node REPL. That's what
the node:12-stretch dockerfile is set up to do via the CMD instruction. We're
overriding that call to the REPL with out custom CMD instruction. The last CMD
found in the dockerfile will be the one that is executed, so if you have two
CMD instructions in your dockerfile like so:

CMD ["node", "-e", "console.log(\"hello"\)"]
CMD ["node", "-e", "console.log(\"hello again"\)"]

when you run your custom container, "hello again" will print, not "hello"


NOTE: You don't need to specify a CMD line (if you are basing your container off
of another one at least). If you don't it will run the default CMD instruction.
You can also run commands that you specify that overrun the CMD instruction like
you would any other conatiner (docker run [CID] ls)

4). From the directory your dockerfile is sitting in you can run:

docker build .

It will assume that you named your dockerfile Dockerfile (if not you can specify)

5). To run your custom container:

docker run [IMAGE ID]

NOTE: you can find the Image ID by running "docker image list" or "docker
images"

6). Give your container a custom tag:

docker build --tag my-node-app .

NOTE: this will default the tage to my-node-app:latest
It's better to version your containers (my-node-app:1.0.0)

7). When you make new versions of the container, it stores the history and you
can run older versions:

    1). docker build --tag my-node-app:1
    2). change the CMD slightly so it prints something different now
    3). docker build --tag my-node-app:2
    4). docker build --tag my-node-app:1

doing this you can see that you can run different versions of your container

NOTE: That when rebuilding the container, the image ID appears to stay the same
until you change the tag at which point a new image and IID is generated.

----------------------------------------------------------------------------------

BUILDING A NODE.JS APP:

Let's say we have a basic node server (index.js):

// Import the http core module
const http = require("http");

// Create an http server on port 3000
http
    .createServer(function(request, response) {
        // Upon receiving a request print that you received it
        console.log("request received");
        // Display a custom response
        response.end("omg hi", "utf-8");
    })
    .listen(3000);

console.log("server started");


running that locally with "node index.js" you'll see the "server started" printout
and then if you go to localhost:3000 in the browser, you'll see "omg hi" displayed on the page.

NOTE: if you look at what is printed out on the terminal, you should see:

server started
request received
request received

the reason why there are two request received printouts is that running index.js
from the browser creates two requests. One of them is requesting the favicon to
display.


We can also package this node code into a custom container that we could use to
run this server:

1). Create a Dockerfile in the same directory as index.js

2). In that Dockerfile:

FROM node:12-stretch

COPY index.js index.js

CMD ["node", "index.js"]


NOTE: The COPY command copies the source (first path) file into the container at
the destination path (second path). If we didn't do this, our container would not
be able to access index.js.


3). Build the custom container:

docker build -t my-node-app .

This will override the previous container we made but that's fine

NOTE: The output of this command shows that during the build command, docker
is actually running each instruction sequentially and creating a valid container
for each step.


4). If you run the node server we created from within the container we made:

docker run my-node-app

We see that if we go to localhost:3000 in the browser, the browser cannot establish
a connection. This is because by default our container is not given access to the
network (certain namespaces are unshared).

You can also see that you can't CTRL+C to end the Node server in the container.
This is because Node does not respond to these kinds of signals (SIGINT in this
case). When we press CTRL+C we're telling docker to pass the SIGINT along to
Node and Node does not process it. There are a couple of ways to solve this
problem:

    1). Deal with it within the Node index.js file we created (process.on
    ('SIGTERM') end the server)

    2). Open another terminal and docker kill the process

    3). When you run your node app within the container use the --init flag:

    docker run --init --rm my-node-app

    This will run the container with a module called tini which will proxy the
    node process and will deal with the SIGTERM/SIGINT signals for you (the --rm
    flag just removes the container once it runs). If you want to run tini in prod
    it's better to go into you Dockerfile, install tini and then run Node from tini
    so that it's built into the container.

    TODO: try to do this right both with tini and dealing with SIGs in index.js



5). To run the container so that it can access port 3000 we run:

docker run --init --rm --publish 3000:3000 my-node-app

NOTE: you could route ports like 3000:8000 (ACTUALLY i tried routing like this
and it didn't work). Allowing port access is probably something you want to be
doing at runtime, so using publish is probably a better idea than using the expose
instruction in the Dockerfile in this case

--------------------------------------------------------------------------------------------

DEALING WITH SIGNALS WITH DOCKER:

The process of passing along signals in docker (at least when running node) is
tricky. I tried adding code that would deal with signals inside of index.js:

'use strict';
const process = require('process');
const http = require('http');

var server = http
  .createServer((req, res) => {
    console.log('Request received');
    res.writeHead(200, {'Content-Type': 'text/plain'});
    res.end('Hello World\n');
  })
  .listen(3000, '0.0.0.0');

  console.log('server started\n');
  // Confirm that this process is running with PID 1
  console.log('PID = ' + process.pid);

  var signals = {
    'SIGINT': 2,
    'SIGTERM': 15
  };

  function shutdown(signal, value) {
    server.close(() => {
      console.log('server stopped by ' + signal);
      process.exit(128 + value);
    });
  }

  Object.keys(signals).forEach((signal) => {
    process.on(signal, () => {
      shutdown(signal, signals[signal]);
    });
  });


Credit to:
https://medium.com/@gchudnov/trapping-signals-in-docker-containers-7a57fdda7d86

https://medium.com/@becintec/building-graceful-node-applications-in-docker-4d2cd4d5d392


This code works great when running node locally outside of a container. It handles signals
does what you would expect. Unfortunately, when you run index.js from a container the
signal is never passed through properly. I believe that when we run the container as it's
built initially, the Node command running the http server is running with PID=1. It seems
that whatever command is in the CMD=[]; line in the dockerfile/executed first has PID=1
and I need to look into why this is causing issues (research online seems to point that it does).
In order to see whether or not the PID made a difference I tried the following (not sure this
is actually sound logic):

1). Created a new version of my-node-app container where in the dockerfile i commented out
the CMD that runs the index.js and just run bash instead.

2). I ran the container in -it mode so that I could launch the server manually:

docker -it --rm my-node-app:1.1.0
node index.js

3). In my index.js code I print out the PID, but I can also just run ps aux. Using that PID,
I passed a SIGINT signal to the node process running within the modified node container:

docker exec [CONTAINER NAME] kill -SIGINT [PID of node index.js running inside the container]

This worked and the signal was handled as specified in index.js. Given that the docker
exec command to kill the process with SIGINT was run from outside the container, I assume
that this mimics what happens when I try to CONTROL+C when running my-node-app version 1.
The main difference is that in the first version, the http server is running on PID 1.
Once again, I'm not sure that my assumptions are correct.


    WRITING A CUSTOM INIT PROCESS:

    https://hackernoon.com/my-process-became-pid-1-and-now-signals-behave-strangely-b05c52cc551c

    1). Create a simple (python) script that just sleeps:

    import subprocess
    subprocess.call(["sleep", "100"])

    2). Run it locally and kill it successfully with SIGTERM (kill [PID] command)

    3). Create a simple dockerfile:

    FROM ubuntu:20.04

    RUN apt-get update
    RUN apt-get install -y python
    COPY mypy.py /srv/

    CMD ["python", "/srv/mypy.py"]


    4). Run the container interactively:

    docker exec -it [CID] bash

    5). Confirm that the process id of the python script is 1 using the ps command (ps -ef)

    6). Try killing the python process (SIGTERM kill [PID] command)

    7). Confirm that the process is still running despite the SIGTERM signal

    NOTE: when runnning a similar setup with Go, it seems to let you SIGTERM.
    A process running as PID 1 inside a container is treated specially by Linux: it ignores
    any signal with the default action. As a result, the process will not terminate on SIGINT
    or SIGTERM unless it is coded to do so. That being said, even when we tried defining
    handlers in our index.js file, it didn't work so I'm not sure what's happening. Also
    PID 1 is responsible for some things behind the scenes so killing it is not always
    adviseable.

    What we'd like to do instead is run a different process as PID 1 that proxy's signals from
    outside the container into the script/server inside the container. We also want that
    process to take care of some other standard initialization things.

    As BH mentioned, Tini does this for us and ships with Docker.


    NOTE: I tried writing my own init based off but I'm going to leave it alone for now and
    come back to it. Just a few notes though:

    1). The basic idea of the init process is that it will take the name of the process
    we want to run as an argument and execute it for us. After starting the process it's
    important to make a Wait call so as to avoid spawning zombie processes.A child that
    terminates, but has not been waited for becomes a "zombie". The kernel maintains a
    minimal set of information about the zombie process (PID, termination status, resource
    usage information) in order to allow the parent to later perform a wait to obtain
    information about the child. As long as a zombie is not removed from the system via a wait,
    it will consume a slot in the kernel process table, and if this table fills, it will
    not be possible to create further processes.

    2). Then you have to write code in your init script to listen for signals and handle
    them. The handler function will ultimately make some sort of system call to kill
    the process via its PID.

    3). PID 1 is also responsible for cleaning up Zombie processes and reparenting
    orphaned processes (A -spawns-> B -spawns-> C. Now if B is killed C does not have a parent
    process and PID 1 is responsible for making C's parent process A. When C exits, A receives
    a SIGCHILD signal and is responsible for calling wait on C to clean up this Zombie process).

    4). You also have to deal with the situation where process B failed to call Wait on C
    and when B is killed, a Zombie C process becomes the child of A. This has to be dealt
    with as well and seems a little tricky (lookup WNOHANG, SIGCHILD, wait4).

    5). Sidenote:  To avoid getting hung up on tzdata config question
    about geographic zone during docker build, I added ARG DEBIAN_FRONTEND=noninteractive to the
    Dockerfile.

--------------------------------------------------------------------------------------------------

BACK TO THE NODE APP:

For now, call:

docker run --init --rm --publish 3000:3000  my-node-app

in order to call tini and not have to worry about the signals. We also call publish to allow
the node app to have access to port 3000.



RUN NODE APP:


